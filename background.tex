\chapter{Background}
\label{chap:background}

This chapter outlines the preliminary information necessary to contextualize the
remainder of this thesis for readers unfamiliar with existing CRDT research.
Here we motivate conflict-free replicated datatypes (CRDTs), formalize state-
and op-based variants of CRDTs, and present examples of common instantiations.
Finally, we conclude with a discussion of the different levels of consistency
guarantees that each CRDT variant offers, and rationalize which levels of
consistency are appealing in certain situations.

\section{Coordinated Replication}
In a distributed system, it is common for more than one participant to need to
have a \textit{view} of the same data. For example, multiple nodes may need to
have access to the same internal data structures necessary to execute some
computation. When a piece of data is shared among many participants in a system,
we say that that data is \textit{replicated}.

However, saying only that some data is ``replicated'' is under-specified. For
example: how often is that data updated among multiple participants? How does
that data behave when multiple participants are modifying it concurrently? Do
all participants always have the same view of the data, or are there temporary
divergences between the participants in the system?

It turns out that the answer of the last question is of paramount importance.
Traditionally speaking, in a distributed system, all participants have an
identical replica of any piece of shared data at all times. That is, at no
moment in time will there be a replica that could atomically compare its
replicated value for some data with any other replica for equality and disagree.
Said otherwise, all replicated values are equal everywhere all at once. This is
an appealing property to say the least, because it allows system designers to
conceptually treat a distributed system as a single unit of computation. That
is, if all replicas maintain the same memory, it is conceptually as if one whole
machine is being replicated many times.

That being said, upholding this requirement is not a straightforward task. An
immediate question arises which is: who coordinates when updates to a piece of
data are replicated to other participants in the system? What happens when the
coordinator becomes unresponsive, or otherwise misbehaves? Who is responsible
for electing a new participant to take over the coordination duties of the
participant which was no longer able to fulfill them?

\section{Distributed Consensus Algorithms}

This gives rise to the area of consensus algorithms. A consensus algorithm,
broadly speaking, is a routine which multiple participants follow in order to
agree on a shared value.

We first state briefly the properties that an algorithm must have to solve
distributed consensus:
\begin{definition}[Distributed Consensus Algorithm, \citep{howard19}]
  \label{def:consensus}
  An algorithm is said to solve distributed consensus if it has the following
  three safety requirements:
  \begin{description}
    \item[Non-triviality] The decided value must have been proposed by a
      participant.
    \item[Safety] Once a value has been decided, no other value will be decided.
    \item[Safe learning] If a participant learns a value, it must learn the
      decided value.
  \end{description}
  In addition, it must satisfy the following two progress requirements:
  \begin{description}
    \item[Progress] Under previously agreed-upon liveness conditions, if a value
      is proposed by a participant, then a value is eventually decided.
    \item[Eventual learning] Under the same conditions as above, if a value is
      decided, then that value must be eventually learned.
  \end{description}
\end{definition}

We summarize the two most popular and often-implemented algorithms for
distributed consensus~\citep{howard20}:

\paragraph{Paxos}
The most popular algorithm in this field is Paxos~\citep{lamport98}. Broadly
speaking, values (corresponding to changing the value of a replicated piece of
data) are \textit{proposed}, \textit{accepted}, and \textit{learned} by
participants in the system. This process is coordinated by an elected
\textit{leader}, which is responsible for communicating with other participants
in order to drive the process forward. When a leader becomes unresponsive, other
participants in the system begin an election process to replace the leader, and
do so when a majority of participants (and the new leader) acknowledge the
  change.

\paragraph{Raft}
Lest we omit another often-implemented consensus algorithm, we briefly discuss
the Raft consensus algorithm as well~\citep{ongaro14}. Raft emphasizes
understandability in its design, and ``separates the key elements of consensus''
by silo-ing replication, leader election, and safety into different sub-problems
at the design level. An execution of Raft consists of several \textit{terms}. To
begin each term, an election is held in order to determine a \textit{leader}.
Once elected, the leader is responsible for disseminating updates to each
replicas copy of the \textit{log}. Conflicting log entries are always resolved
in favor of the leader's copy. Finally, Raft enforces safety by imposing
additional restrictions on the behavior of a term such that the log replication
strategy is proven to be safe. This is argued in~\citep{ongaro14} and
mechanically verified in~\citep{wilcox15}.

\subsection{Safety in Distributed Consensus Algorithms}

Both Raft and Paxos are notoriously difficult to implement correctly in
practice~\citep{howard20}. Distributed consensus algorithms are often the
subject of undergraduate-level courses in networks and distributed systems.
Often, commercially-available implementations of these algorithms are built into
off the shelf solutions, such as Apache Zookeeper and CoreOS's

It is a natural question to ask why these algorithms are so notoriously
difficult to implement in practice. Individually, the properties
in Definition~\ref{def:consensus} seem reasonably in their own right. We propose
that it is the safety property (that once a value has been decided, no other
values will be decided) that makes implementing these algorithms correctly so
difficult in practice. In essence, coordinating the proposals individual
participants submit is the central difficulty of these algorithms.

Conflict-free Replicated Datatypes (CRDTs) are a natural answer to this
question. By allowing participants to temporarily diverge from the state of the
overall computation (c.f., the second property of
Definition~\ref{def:eventual-consistency}), CRDTs allow replicas to violate the
safety property of Definition~\ref{def:consensus}. By giving up the immediacy
and permanence that the safety properties of a traditional distributed consensus
algorithm, CRDTs allow for a dramatically lower implementation burden in
practice, and are substantially easier to reason about.

\section{state-based CRDTs}
We begin with a discussion of state-based CRDTs from their inception
in~\citep{shapario11}. A state-based CRDT is a 5-tuple $(S, s^0, q, u, m)$. An
individual replica of a state-based CRDT is at some state $s^i \in S$ for $i \ge
0$, and is initially $s^0$. The value may be queried by any client or other
replica by invoking $q$. It may be updated with $u$, which has a unique type per
CRDT object. Finally, $m$ merges the state of some other remote replica.

Crucially, the states of a given state-based CRDT form a partially-ordered set
$\langle S, \sqsubseteq \rangle$. This poset is used to form a join
semi-lattice, where any finite subset of elements has a natural least
upper-bound. Consider two elements $s^m, s^n \in S$. The least upper-bound
$s = s^m \sqcup s^n$ is given as:
\[
  \forall s'.\; s' \sqsupseteq s^m, s^n \Rightarrow
    s^m \sqsubseteq s \land
    s^n \sqsubseteq s \land
    s \sqsubseteq s'
\]
In other words, a $s = s^m \sqcup s^n$ is a least upper-bound of $s^m$ and $s^n$
if it is the smallest element that is at least as large as both $s^m$ and $s^n$.

\section{op-based CRDTs}
\label{sec:op-based-crdts}

\section{Conflict Free Replicated Datatypes}
\subsection{Example: Grow-Only Counter}
\label{sec:example-gcounter}

\subsection{Example: PN-Counter}
\subsection{Example: OR-Set}
\section{Consistency Guarantees}
\subsection{Causal Consistency}
\subsection{Eventual Consistency}
\subsection{Strong Eventual Consistency}
\section{Network Semantics}
