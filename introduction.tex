\chapter{Introduction}

Computational systems today are larger than ever. Whereas previously one would
architect their programs to run on a single system, it is now commonplace to
design programs that share computation across multiple machines which
communicate with each other in a coordinated fashion. Therefore, it is natural
to ask why one might design from the latter perspective rather than the former.
The answer is threefold:
\begin{enumerate}
  \item \emph{Resiliency}. Designing a computational workload to be distributed
    among participants tolerates the failure of any one (or more) of those
    participants.
  \item \emph{Scalability}. When designed from a distributed standpoint,
    ``scaling'' your workload to meet a higher demand is reduced to adding
    additional hardware, not designing more efficient ways to do the
    computation.
  \item \emph{Locality}. When a system is accessed from a broad set of
    geographic locations, strategic placement of hardware in locations near
    request-origin sites can lower latency for users.
\end{enumerate}

So, it is clear that as our demand on such computations grow, that so too
must our need to design these systems in a way that first considers the concerns
of resiliency, scalability, and locality.

In order to design systems in this way, however, one must consider additionally
the challenges imposed by not having access to shared memory among participants
in the computation. If a program runs in a single-threaded fashion on a single
computer, there is no need to coordinate memory accesses, since only one part of
the program may read or write memory at a given time. If the program is written
to be multithreaded, then the threads must coordinate among themselves by using
mutexes or communication channels to avoid race conditions and other concurrency
errors.

The same challenge exists when a system is distributed at the hardware and
machine level, rather than among multiple threads running on a single piece of
hardware. The challenge, however, is made more difficult by the fact that the
communication overhead is far higher between separate pieces of hardware than
between two threads.

This thesis focuses on datatypes by which computation can be coordinated across
multiple machines. In particular, we formalize a set of consistency guarantees
(namely, Strong Eventual Consistency, hereafter \SEC) over a class of replicated
datatypes, $\delta$-Conflict-Free Replicated Datatypes (\CRDTs). We describe the
preliminaries necessary to contextualize the body of this work in the following
section.

\section{Preliminaries}
Our discussion here focuses on the class of \CRDTs, which are designed to be
both easily distributed and require relatively low coordination overhead by
allowing individual participants to diverge temporarily from the state of the
overall computation. That is, the computation reflects a different value
depending on which participant in the computation responds to the request.

These datatypes operate in such a way so as to both avoid conflict between
concurrent updates, and to avoid locking and coordination
overhead~\citep{shapiro11}. \CRDTs have seen moderate use in industry, too.
Based on introspection of the runtime headers in iOS, Apple is believed to use a
state-based \CRDT for offline synchronization of content in their note-taking
app, Notes~\citep{applenotes}.  Redis, a popular open-source distributed cache
uses \CRDTs in their Enterprise offering to perform certain kinds of replication
and conflict-resolution~\citep{redis}.

\CRDTs are said to achieve \SEC which is to say that they achieve a stronger
form of \textit{eventual consistency} (\EC). We summarize the definitions of
eventual- and strong-eventual consistency from~\cite{shapiro11}.

\begin{definition}[Eventual Consistency]
  \label{def:eventual-consistency}
  A replicated datatype is \emph{eventually consistent} if:
  \begin{itemize}
    \item Updates delivered to it are eventually delivered to all other replicas
      in the system.
    \item All well-behaved replicas that have received the same set of updates
      eventually reflect the same state.
    \item All executions on this datatype are terminating.
  \end{itemize}
\end{definition}

\begin{definition}[Strong Eventual Consistency]
  A replicated datatype is \emph{strong eventually consistent} if:
  \begin{itemize}
    \item It is eventually consistent, as above.
    \item Convergence occurs immediately, that is, any two replicas that have
      received the same set of updates \emph{always} reflect the same state.
  \end{itemize}
\end{definition}

Broadly speaking, there are two classes of \CRDTs, which we refer to as the op-
and state-based variants. We will provide formal definitions for each of the two
classes in Chapter~\ref{chap:background}, but will describe each class
informally below.

We now present brief definitions of op- and state-based \CRDTs based
on~\citet{baquero14}:

\begin{definition}[Operation-based Conflict-Free Replicated Datatype (op-based
\CRDT)]
  op-based \CRDTs apply updates in two phases:
  \begin{enumerate}
    \item First, an operation is \emph{prepared} locally. At this phase, the
      op-based \CRDT combines the operation with the current state to send a
      representation of the update to other replicas.
    \item Then, the represented operation is applied to other replicas using
      \emph{effect}, where \emph{effect} is commutative for concurrent
      operations.
  \end{enumerate}
\end{definition}

\begin{definition}[State-based Conflict-Free Replicated Datatype (state-based
\CRDT)]
  state-based \CRDTs only apply updates to their local state, and periodically
  send serialized representations of the contents of their state to other
  replicas.

  Crucially, these states form a \textit{monotone join semi-lattice} (i.e,. a
  lattice $\langle S, \sqcup \rangle$ where for any $s_1, s_2 \in S$ at both
  $s_1 \sqsubseteq s_1 \sqcup s_2$ and $s_2 \sqsubseteq s_1 \sqcup s_2$ hold for
  commutative, associative, and idempotent $\sqcup$).

  To achieve convergence, state-based \CRDTs periodically send their state to
  other replicas, which then replace their own state by joining the received
  state into their own.
\end{definition}

\section{op- and state-based trade-offs}

These two classes are distinguished from one another based on their strengths
and weaknesses. In one sense, op- and state-based \CRDTs form a kind of a dual,
where they trade off strong network guarantees for message payload
size~\citep{baquero14}.

Because the state-based \CRDT needs to send a representation of its entire
state, it often requires a significant amount of network bandwidth to propagate
large messages~\citep{almedia18}. In Section~\ref{sec:example-gcounter} we will
present an example where the payload size grows as a linear function of the
number of replicas. In return for this large payload size, state-based \CRDTs
are able to achieve \SEC even in networks that are allowed to drop, reorder, and
duplicate messages.

On the other hand, op-based \CRDTs require relatively little network bandwidth
to send a notification of a single update (typically the representation
generated in the \textit{prepare} stage is dwarfed by the typical payload size
of a state-based \CRDT), but in exchange demand that the network deliver
messages in-order for sequential (comparable) updates and
at-most-once~\citep{shapiro11}.

Significant work in this area~\cite{almedia18, enes18, cabrita17, vanDerLinde16}
has focused on mediating these two extremes. This line of research (particularly
in~\citet{almedia18}) has identified $\delta$-state \CRDTs---a variant of the
state-based \CRDT which we discuss in Section~\ref{sec:state-based-crdts}---as
an alternative which occupies a satisfying position between the two extremes.
$\delta$-state \CRDTs behave as traditional state-based \CRDTs, with the
exception that their updates consist of state \emph{fragments} instead of their
entire state. These fragments (generated by $\delta$-mutators and called
$\delta$-updates) are then applied locally at all other replicas to reassemble
the full state. Because these fragments often do not need to comprise the full
state, $\delta$-state \CRDTs in general have small payload size (thus requiring
a similar amount of bandwidth as messages sent and received from op-based
\CRDTs), while still tolerating the same set of network deficiencies as
state-based \CRDTs. This combination of properties makes them an appealing
alternative to traditional state- and op-based \CRDTs, and places interest in
studying their convergence properties.

\section{Contributions}

Our main contribution builds on the work in~\citet{gomes17} and introduces a set
of formal, machine-checked proofs in Isabelle~\citep{wenzel02} of the main
result in~\citet{almedia18}, which we re-state below:

\begin{theorem}[Almedia, Shoker, Baquero, '18]
  Consider a set of replicas of a $\delta$-\CRDT object, replica $i$ evolving
  along a sequence of states $X_i^0 = \bot$, $X_i^1=\ldots$, , each replica
  performing delta-mutations of the form $m^\delta_{i,k}(X^k_i)$ at some subset
  of its sequence of states, and evolving by joining the current state either
  with self-generated deltas or with delta-groups received from others. If each
  delta-mutation $m^\delta _{i,k}(X^k_i)$ produced at each replica is joined
  (directly or as part of a delta-group) at least once with every other replica,
  all replica states become equal.
\end{theorem}

Here, $X_i^t$ refers to the state of replica $i$ at time $t$, and
$m^\delta_{i,k}$ refers to the $\delta$-mutation applied at the $i$th replica
$i$ at time $k$.

In other words, we rely on the work of~\citet{gomes17} in order to build a
handful of $\delta$-state \CRDTs as in~\citet{almedia18} and show that even
under weak network guarantees\footnote{We inherit dropping and reordering of
messages from the original work of~\citet{gomes17}, but further relax the
network model by also allowing messages to be duplicated.} these $\delta$-state
\CRDTs still achieve \SEC.

Our verification efforts yielded a pair of \CRDTs---the grow-only counter
(G-Counter) and set (G-Set)---in three encodings: one state-based, and two
$\delta$-state encodings. Our key idea guiding these verification efforts is to
treat op- and state-based \CRDTs similarly by modeling state-based \CRDTs as
op-based where the operation is the join provided by the
semi-lattice.\footnote{This approach is described in detail in
Section~\ref{sec:state-as-op}.} We generalize state- and $\delta$-state \CRDTs
into a new class called \emph{generalized state-based \CRDTs}, and then use
these ideas to verify state- and $\delta$-state \CRDTs on top of the library
provided in~\citet{gomes17}.  We show that the
$\isa{strong}{\isacharunderscore}\isa{eventual}{\isacharunderscore}\isa{consistency}$
locale can still be instantiated over these \CRDTs, even when the underlying
$\isa{network}$ locale has been weakened substantially from when it was
introduced in the aforementioned work.

The remainder of this thesis is ordered as follows:
\begin{itemize}
  \item In Chapter~\ref{chap:background}, we summarize existing research in the
    broader realm of conflict-free replicated datatypes. We present formal
    definitions of op- and state-based \CRDTs, and conduct a thorough discussion
    of their relative strengths and weaknesses. Likewise, we present a summary
    of some work in the area of $\delta$-state \CRDTs, and present its
    strengths.
  \item In Chapter~\ref{chap:crdt-instantiations}, we discuss examples of two
    \CRDTs in an op-, state-, and $\delta$-state style. These objects will be
    the subject of our verification efforts in Chapter~\ref{chap:example-crdts}.
  \item In Chapter~\ref{chap:crdt-reductions}, we outline a pair of reductions
    between state-, op-, and $\delta$-state based \CRDTs which guides the
    majority of our proof strategy. We also define the class of
    \emph{generalized state-based \CRDTs}.
  \item In Chapter~\ref{chap:example-crdts}, we discuss the outcome of our
    approach by presenting a pair of successfully-verified $\delta$-state
    \CRDTs, as well as describe our efforts in relaxing the network model in
    order to verify these objects over a non-trivial set of network behaviors.
  \item In Chapter~\ref{chap:future-work}, we suggest future
    research directions. We consider a handful of areas in which formalizing
    existing results may be fruitful, as well as a handful of additional
    approaches to the proofs we presented here.
  \item In Chapter~\ref{chap:conclusion}, we conclude.
\end{itemize}
